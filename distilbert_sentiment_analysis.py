# -*- coding: utf-8 -*-
"""DistilBERT-sentiment-analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LNnQvDB2gY6Av5p5bDvD3MFUeYK7qQw4
"""

!pip install -q transformers datasets accelerate

import json
import random
import os

import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay

from torch.utils.data import Dataset
from transformers import (DistilBertTokenizerFast, DistilBertForSequenceClassification,
                          TrainingArguments, Trainer)

import matplotlib.pyplot as plt

"""**Load the dataset**"""

json_path = "/content/all_reviews.json"

# Flatten the dataset
with open(json_path, "r", encoding="utf-8") as f:
    raw = json.load(f)

# raw is a list of lists; each element is a list of review dicts
rows = []
for block in raw:
    for review in block:
        rows.append(review)

df = pd.DataFrame(rows)
print(df.head())
print(df.columns)
print("Rows:", len(df))

"""**Clean the dataset**"""

# Keep only rows with both Comment and Quality
df = df.dropna(subset=["Comment", "Quality"]).copy()

# Remove comments like "No Comments" / "No Comment"
df["Comment"] = df["Comment"].astype(str)
mask_no_comment = df["Comment"].str.strip().str.lower().isin(["no comments", "no comment"])
df = df[~mask_no_comment].copy()

df["Quality"] = df["Quality"].astype(float)

"""**Create sentiment labels**"""

def quality_to_sentiment(q):
    if q <= 2.0:
        return "negative"
    elif q >= 4.0:
        return "positive"
    else:
        return "neutral"

df["sentiment"] = df["Quality"].apply(quality_to_sentiment)
print(df["sentiment"].value_counts())

"""**Map sentiments to numeric labels**"""

label_names = ["negative", "neutral", "positive"]
label2id = {lab: i for i, lab in enumerate(label_names)}
id2label = {i: lab for lab, i in label2id.items()}

df["label"] = df["sentiment"].map(label2id)

df_model = df[["Comment", "Quality", "sentiment", "label"]].rename(columns={"Comment": "text"})
df_model.head()

"""**Train/Test split**"""

train_df, test_df = train_test_split(df_model, test_size=0.2,
                                     random_state=42,
                                      stratify=df_model["label"])

train_df = train_df.reset_index(drop=True)
test_df = test_df.reset_index(drop=True)

print("Train size:", len(train_df), " Test size:", len(test_df))

"""**Set random seeds**"""

seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(seed)

"""**Tokenizer and custom dataset**"""

model_name = "distilbert-base-uncased"
tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)

class ReviewsDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=256):
        self.texts = list(texts)
        self.labels = list(labels)
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = int(self.labels[idx])

        enc = self.tokenizer(text, truncation=True,
                             padding="max_length",
                             max_length=self.max_length,
                             return_tensors="pt")

        # squeeze batch dimension (from (1, seq_len) to (seq_len,))
        item = {k: v.squeeze(0) for k, v in enc.items()}
        item["labels"] = torch.tensor(label, dtype=torch.long)
        return item

train_dataset = ReviewsDataset(train_df["text"], train_df["label"], tokenizer)
test_dataset  = ReviewsDataset(test_df["text"],  test_df["label"],  tokenizer)

len(train_dataset), len(test_dataset)

"""**DistilBERT Model + Trainer**"""

num_labels = len(label_names)

model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels,
                                                            id2label=id2label, label2id=label2id)

os.environ["WANDB_DISABLED"] = "true"       # disable wandb in Colab

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    acc = accuracy_score(labels, preds)
    f1  = f1_score(labels, preds, average="macro")
    return {"accuracy": acc, "macro_f1": f1}

training_args = TrainingArguments(
    output_dir="distilbert_prof_reviews",
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    learning_rate=2e-5,
    weight_decay=0.01,
    logging_steps=50)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics)

"""**Train & Evaluate**"""

train_output = trainer.train()
print(train_output)

eval_results = trainer.evaluate()
eval_results

"""**Confusion Matrix on test set**"""

pred_output = trainer.predict(test_dataset)
y_true = test_df["label"].to_numpy()
y_pred = np.argmax(pred_output.predictions, axis=-1)

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)
fig, ax = plt.subplots(figsize=(5, 4))
disp.plot(ax=ax, values_format="d")
plt.title("Confusion Matrix - DistilBERT Professor Reviews")
plt.tight_layout()
plt.show()

"""**predict_sentiment**"""

def predict_sentiment(texts):
    if isinstance(texts, str):
        texts = [texts]

    enc = tokenizer(texts, padding=True,
                    truncation=True,
                    max_length=256,
                    return_tensors="pt")

    model.eval()
    with torch.no_grad():
        outputs = model(**enc)
        probs = F.softmax(outputs.logits, dim=-1)
        preds = torch.argmax(probs, dim=-1).tolist()

    results = []
    for text, p_id, p_vec in zip(texts, preds, probs):
        label = id2label[p_id]
        conf = float(p_vec[p_id])
        results.append({"text": text, "predicted_label": label, "confidence": conf})
    return results

"""**Example predictions**"""

examples = ["Really passionate professor and clearly knows the material. Lectures can go long but you actually learn a lot. Easy grader if you show effort.",
            "Not the most exciting lecturer, but exams are straightforward if you study and pay attention.",
            "Lots of rambling and little structure. Ended up teaching myself most of the material.",
            "Knows the material really well, but talks most of the class and doesnâ€™t encourage much discussion.",
            "Hard class, but totally worth it. He expects a lot, but you walk away understanding the subject way better.",
            "Nice person and pretty chill class, but lectures can be boring and feel unstructured at times.",
            "Nice enough person, but teaching style makes the class very hard to follow. I struggled a lot. I wouldn't recommend.",
            "Avoid if possible. Way more work than expected and grading felt unfair most of the time."]

for r in predict_sentiment(examples):
    print("TEXT:", r["text"])
    print("PRED:", r["predicted_label"], f"(conf={r['confidence']:.3f})")
    print("-" * 60)